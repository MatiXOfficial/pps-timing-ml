{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "PWD = '../../..'\n",
    "sys.path.append(PWD)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import callbacks\n",
    "import keras_tuner as kt\n",
    "\n",
    "from src.network_utils import count_params\n",
    "from src.cross_validator import KerasTunerCrossValidator\n",
    "from src.dataset import load_dataset_train_test, load_dataset_train_val\n",
    "from src.models import hp_mlp_builder as hp_model_builder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "DATASET_PATH = PWD + '/data/dataset/dataset.pkl'\n",
    "TRIALS_DIR = PWD + '/data/tuner'\n",
    "CROSSVAL_DIR = PWD + '/data/cross_val'\n",
    "\n",
    "PLANE = 2\n",
    "CHANNEL = 11\n",
    "\n",
    "PROJECT_NAME = f'mlp_{PLANE}_{CHANNEL}'\n",
    "\n",
    "LR = 0.01\n",
    "\n",
    "N_EPOCHS = 3000\n",
    "BATCH_SIZE = 2048\n",
    "MAX_TRIALS = 40\n",
    "EXECUTIONS_PER_TRIAL = 2\n",
    "\n",
    "TOP_N = 5\n",
    "CROSSVAL_N_CV = 5\n",
    "CROSSVAL_N_EXEC = 2\n",
    "LOSS_WEIGHT = 1000"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "((22412, 24), (17929, 24), (4483, 24))"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_base_train, _, y_base_train, _ = load_dataset_train_test(PWD, PLANE, CHANNEL)\n",
    "X_train, X_val, y_train, y_val = load_dataset_train_val(PWD, PLANE, CHANNEL)\n",
    "\n",
    "X_base_train.shape, X_train.shape, X_val.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def model_builder(hp: kt.HyperParameters) -> keras.Model:\n",
    "    model = hp_model_builder(hp)\n",
    "    model.compile(loss='mse', optimizer=optimizers.Adam(LR), loss_weights=LOSS_WEIGHT)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 24)                600       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 12)                300       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 913\n",
      "Trainable params: 913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_builder(kt.HyperParameters()).summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "model_callbacks = [\n",
    "    callbacks.EarlyStopping(patience=50),\n",
    "    callbacks.ReduceLROnPlateau(monitor='loss', factor=0.9, patience=10),\n",
    "    callbacks.TensorBoard(\"/tmp/tb_logs/bayesian/\" + PROJECT_NAME)\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Bayesian tuner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "bayesian_tuner = kt.BayesianOptimization(model_builder, objective='val_loss', executions_per_trial=EXECUTIONS_PER_TRIAL,\n",
    "                                         max_trials=MAX_TRIALS, directory=TRIALS_DIR + \"/bayesian\",\n",
    "                                         project_name=PROJECT_NAME, overwrite=False)\n",
    "\n",
    "bayesian_tuner.search(X_train, y_train, validation_data=[X_val, y_val], epochs=N_EPOCHS, callbacks=model_callbacks,\n",
    "                      batch_size=BATCH_SIZE, verbose=3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in ../../../data/tuner/bayesian\\mlp_2_11\n",
      "Showing 1 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x000001A7D5E4DAB0>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_hidden_layers: 1\n",
      "units_mult: 32\n",
      "batch_normalization: True\n",
      "input_batch_normalization: True\n",
      "dropout: 0.2\n",
      "Score: 8.616175651550293\n"
     ]
    }
   ],
   "source": [
    "bayesian_tuner.results_summary(1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization (BatchN  (None, 24)               96        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 96)                2400      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 96)               384       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 96)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 97        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,977\n",
      "Trainable params: 2,737\n",
      "Non-trainable params: 240\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model = bayesian_tuner.get_best_models(num_models=1)[0]\n",
    "best_model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model 0 ==========\n",
      "{'n_hidden_layers': 1, 'units_mult': 32, 'batch_normalization': True, 'input_batch_normalization': True, 'dropout': 0.2}\n",
      "Number of parameters: 2737\n",
      "========== Model 1 ==========\n",
      "{'n_hidden_layers': 6, 'units_mult': 8, 'batch_normalization': True, 'input_batch_normalization': True, 'dropout': 0.2}\n",
      "Number of parameters: 415873\n",
      "========== Model 2 ==========\n",
      "{'n_hidden_layers': 4, 'units_mult': 32, 'batch_normalization': True, 'input_batch_normalization': True, 'dropout': 0.5}\n",
      "Number of parameters: 409969\n",
      "========== Model 3 ==========\n",
      "{'n_hidden_layers': 4, 'units_mult': 8, 'batch_normalization': True, 'input_batch_normalization': True, 'dropout': 0.2}\n",
      "Number of parameters: 29953\n",
      "========== Model 4 ==========\n",
      "{'n_hidden_layers': 1, 'units_mult': 32, 'batch_normalization': True, 'input_batch_normalization': True, 'dropout': 0.5}\n",
      "Number of parameters: 2737\n"
     ]
    }
   ],
   "source": [
    "for i, hyperparameters in enumerate(bayesian_tuner.get_best_hyperparameters(TOP_N)):\n",
    "    print(f'========== Model {i} ==========')\n",
    "    print(hyperparameters.get_config()['values'])\n",
    "    model_tmp = model_builder(hyperparameters)\n",
    "    print('Number of parameters:', count_params(model_tmp))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in ../../../data/tuner/bayesian\\mlp_2_11\n",
      "Showing 5 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x000001A7D5E4DAB0>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_hidden_layers: 1\n",
      "units_mult: 32\n",
      "batch_normalization: True\n",
      "input_batch_normalization: True\n",
      "dropout: 0.2\n",
      "Score: 8.616175651550293\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_hidden_layers: 6\n",
      "units_mult: 8\n",
      "batch_normalization: True\n",
      "input_batch_normalization: True\n",
      "dropout: 0.2\n",
      "Score: 8.616738319396973\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_hidden_layers: 4\n",
      "units_mult: 32\n",
      "batch_normalization: True\n",
      "input_batch_normalization: True\n",
      "dropout: 0.5\n",
      "Score: 8.62345552444458\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_hidden_layers: 4\n",
      "units_mult: 8\n",
      "batch_normalization: True\n",
      "input_batch_normalization: True\n",
      "dropout: 0.2\n",
      "Score: 8.625433921813965\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_hidden_layers: 1\n",
      "units_mult: 32\n",
      "batch_normalization: True\n",
      "input_batch_normalization: True\n",
      "dropout: 0.5\n",
      "Score: 8.635278701782227\n"
     ]
    }
   ],
   "source": [
    "bayesian_tuner.results_summary(TOP_N)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cross-validation for top 5 models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Model 0</h3>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_hidden_layers': 1, 'units_mult': 32, 'batch_normalization': True, 'input_batch_normalization': True, 'dropout': 0.2}\n",
      "Number of parameters: 2737\n",
      "Got score: 8.8293 (8.6711, 8.9874)\n",
      "Got score: 8.5013 (8.4773, 8.5253)\n",
      "Got score: 8.3701 (8.6066, 8.1336)\n",
      "Got score: 8.4792 (8.5149, 8.4434)\n",
      "Got score: 9.0057 (8.9365, 9.0748)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Model 1</h3>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_hidden_layers': 6, 'units_mult': 8, 'batch_normalization': True, 'input_batch_normalization': True, 'dropout': 0.2}\n",
      "Number of parameters: 415873\n",
      "Got score: 8.6687 (8.6840, 8.6534)\n",
      "Got score: 8.3458 (8.3437, 8.3479)\n",
      "Got score: 8.1702 (8.1905, 8.1500)\n",
      "Got score: 8.4881 (8.4061, 8.5701)\n",
      "Got score: 8.7439 (8.7474, 8.7404)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Model 2</h3>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_hidden_layers': 4, 'units_mult': 32, 'batch_normalization': True, 'input_batch_normalization': True, 'dropout': 0.5}\n",
      "Number of parameters: 409969\n",
      "Got score: 8.6625 (8.6255, 8.6994)\n",
      "Got score: 8.3671 (8.3632, 8.3710)\n",
      "Got score: 8.4500 (8.6302, 8.2699)\n",
      "Got score: 8.4509 (8.4019, 8.5000)\n",
      "Got score: 8.8499 (8.9026, 8.7972)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Model 3</h3>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_hidden_layers': 4, 'units_mult': 8, 'batch_normalization': True, 'input_batch_normalization': True, 'dropout': 0.2}\n",
      "Number of parameters: 29953\n",
      "Got score: 8.6717 (8.6764, 8.6670)\n",
      "Got score: 8.3455 (8.3511, 8.3399)\n",
      "Got score: 8.1547 (8.1805, 8.1288)\n",
      "Got score: 8.3960 (8.3946, 8.3975)\n",
      "Got score: 8.7498 (8.7400, 8.7595)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Model 4</h3>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_hidden_layers': 1, 'units_mult': 32, 'batch_normalization': True, 'input_batch_normalization': True, 'dropout': 0.5}\n",
      "Number of parameters: 2737\n",
      "Got score: 8.7009 (8.7119, 8.6898)\n",
      "Got score: 8.4356 (8.3942, 8.4770)\n",
      "Got score: 8.2475 (8.2652, 8.2297)\n",
      "Got score: 8.6567 (8.6134, 8.7000)\n",
      "Got score: 8.9669 (8.9988, 8.9351)\n"
     ]
    }
   ],
   "source": [
    "cross_validator = KerasTunerCrossValidator(bayesian_tuner, X_base_train, y_base_train, model_builder,\n",
    "                                           directory=CROSSVAL_DIR, project_name=PROJECT_NAME,\n",
    "                                           n_epochs=N_EPOCHS, batch_size=BATCH_SIZE, n_top=TOP_N,\n",
    "                                           n_cv=CROSSVAL_N_CV, n_executions=CROSSVAL_N_EXEC, overwrite=False)\n",
    "model_scores = cross_validator()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "       mean   std  n_params\nModel                      \n0      8.64  0.24      2737\n1      8.48  0.21    415873\n2      8.56  0.18    409969\n3      8.46  0.22     29953\n4      8.60  0.24      2737",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean</th>\n      <th>std</th>\n      <th>n_params</th>\n    </tr>\n    <tr>\n      <th>Model</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8.64</td>\n      <td>0.24</td>\n      <td>2737</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8.48</td>\n      <td>0.21</td>\n      <td>415873</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8.56</td>\n      <td>0.18</td>\n      <td>409969</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8.46</td>\n      <td>0.22</td>\n      <td>29953</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8.60</td>\n      <td>0.24</td>\n      <td>2737</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_scores = [f\"{np.mean(scores):0.2f}\" for scores in model_scores.values()]\n",
    "std_scores = [f\"{np.std(scores):0.2f}\" for scores in model_scores.values()]\n",
    "n_params = [count_params(model_builder(hyperparameters)) for hyperparameters in\n",
    "            bayesian_tuner.get_best_hyperparameters(TOP_N)]\n",
    "\n",
    "df = pd.DataFrame({'mean': mean_scores, 'std': std_scores, 'n_params': n_params}, index=model_scores.keys())\n",
    "df.index.name = 'Model'\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
