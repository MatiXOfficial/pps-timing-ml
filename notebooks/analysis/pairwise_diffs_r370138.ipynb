{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-21T10:57:13.950420Z",
     "start_time": "2023-07-21T10:57:10.204313900Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Self' from 'typing' (C:\\Users\\MatiX\\miniconda3\\envs\\cern-ml\\lib\\typing.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 16\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pyplot \u001B[38;5;28;01mas\u001B[39;00m plt\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel_selection\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m train_test_split\n\u001B[1;32m---> 16\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdataset\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m load_expanded_dataset_train_test, ExpandedDataset\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgauss_hist\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m plot_gauss_hist\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01miti\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m build_nn_dataset, build_and_train_network, build_updated_dataset, compute_pairwise_precisions\n",
      "File \u001B[1;32mC:\\Repository\\pps-timing-ml-sampic\\src\\dataset.py:5\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdataclasses\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m dataclass\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpathlib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Path\n\u001B[1;32m----> 5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Iterable, Self\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel_selection\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m train_test_split\n",
      "\u001B[1;31mImportError\u001B[0m: cannot import name 'Self' from 'typing' (C:\\Users\\MatiX\\miniconda3\\envs\\cern-ml\\lib\\typing.py)"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import math\n",
    "import pickle\n",
    "import sys\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.dataset import load_expanded_dataset_train_test, ExpandedDataset\n",
    "from src.gauss_hist import plot_gauss_hist\n",
    "from src.iti import build_nn_dataset, build_and_train_network, build_updated_dataset, compute_pairwise_precisions\n",
    "from src.models import optimal_model_builder_all_ch\n",
    "from src.network_utils import plot_history\n",
    "from src.utils import deconvolve_precisions, save_plt, PLANES, PLANE_0, N_PLANES\n",
    "\n",
    "PWD = '../..'\n",
    "sys.path.append(PWD)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "DIR_NAME = 'pairwise_diffs_r370138'\n",
    "ARTIFACT_DIR = Path(PWD) / Path('data/analysis/pairwise_diffs_r370138')\n",
    "\n",
    "EXPANDED_DATASET_PATH_R354332 = Path(PWD) / Path('data/dataset/dataset_exp_r354332.pkl')\n",
    "EXPANDED_DATASET_PATH_R355207 = Path(PWD) / Path('data/dataset/dataset_exp.pkl')\n",
    "EXPANDED_DATASET_PATH_R370138 = Path(PWD) / Path('data/dataset/dataset_exp_r370138.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "OVERWRITE = False\n",
    "\n",
    "LR = 0.05\n",
    "ES_MIN_DELTA = 0.01\n",
    "\n",
    "N_EPOCHS = 500\n",
    "BATCH_SIZE = 8192\n",
    "LOSS_WEIGHT = 1000\n",
    "\n",
    "LR_PATIENCE = 4\n",
    "ES_PATIENCE = 20\n",
    "\n",
    "VERBOSE = 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(EXPANDED_DATASET_PATH_R354332, 'rb') as file:\n",
    "    dataset_r354332 = pickle.load(file)\n",
    "\n",
    "with open(EXPANDED_DATASET_PATH_R355207, 'rb') as file:\n",
    "    dataset_r355207 = pickle.load(file)\n",
    "\n",
    "with open(EXPANDED_DATASET_PATH_R370138, 'rb') as file:\n",
    "    dataset_r370138 = pickle.load(file)\n",
    "\n",
    "train_datasets = [dataset_r354332, dataset_r355207]\n",
    "test_dataset = dataset_r370138\n",
    "\n",
    "train_datasets[0].t_avg.shape, test_dataset.t_avg.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CFD"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pairwise_precisions_stat, pairwise_precisions_gauss_cfd = compute_pairwise_precisions(\n",
    "    test_dataset, hists_path=ARTIFACT_DIR / 'pairwise_diff_hists_trained_cfd', show=False\n",
    ")\n",
    "\n",
    "avg_prec_stat = np.average(list(pairwise_precisions_stat.values()))\n",
    "avg_prec_gauss = np.average(list(pairwise_precisions_gauss_cfd.values()))\n",
    "\n",
    "print(f\"Average precision; stat: {avg_prec_stat:6.2f} ps; Gauss {avg_prec_gauss:6.2f} ps\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "deconvolved_precisions_gauss_cfd = deconvolve_precisions(pairwise_precisions_gauss_cfd)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# NN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train, x_train_t, y_train = [], [], []\n",
    "for train_dataset in train_datasets:\n",
    "    x_train_tmp, y_train_t_tmp, y_train_tmp = build_nn_dataset(train_dataset, use_t_avg=True)\n",
    "    x_train.append(x_train_tmp)\n",
    "    x_train_t.append(y_train_t_tmp)\n",
    "    y_train.append(y_train_tmp)\n",
    "\n",
    "x_train = np.concatenate(x_train)\n",
    "x_train_t = np.concatenate(x_train_t)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "x_test, y_test_t, y_test = build_nn_dataset(test_dataset, use_t_avg=True)\n",
    "\n",
    "x_train.shape, x_test.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model, history = build_and_train_network(iteration=None, x_train=x_train, x_val=x_test, y_train=y_train, y_val=y_test,\n",
    "                                         overwrite=OVERWRITE, pwd=PWD, dir_name=DIR_NAME, lr=LR, n_epochs=1,\n",
    "                                         batch_size=BATCH_SIZE, lr_patience=LR_PATIENCE, es_patience=ES_PATIENCE,\n",
    "                                         es_min_delta=ES_MIN_DELTA, loss_weight=LOSS_WEIGHT, verbose=VERBOSE,\n",
    "                                         model_builder=optimal_model_builder_all_ch)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_history(history, ymax=20, show=True, title=f'loss curve')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_dataset_updated = build_updated_dataset(model, test_dataset, BATCH_SIZE, log=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pairwise_precisions_stat, pairwise_precisions_gauss_nn = compute_pairwise_precisions(\n",
    "    test_dataset_updated, hists_path=ARTIFACT_DIR / 'pairwise_diff_hists_trained_nn', show=True\n",
    ")\n",
    "\n",
    "avg_prec_stat = np.average(list(pairwise_precisions_stat.values()))\n",
    "avg_prec_gauss = np.average(list(pairwise_precisions_gauss_nn.values()))\n",
    "\n",
    "print(f\"Average precision; stat: {avg_prec_stat:6.2f} ps; Gauss {avg_prec_gauss:6.2f} ps\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "deconvolved_precisions_gauss_nn = deconvolve_precisions(pairwise_precisions_gauss_nn)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Pairwise - CFD:')\n",
    "pprint(pairwise_precisions_gauss_cfd)\n",
    "print('Pairwise - NN:')\n",
    "pprint(pairwise_precisions_gauss_nn)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Gauss:')\n",
    "for p_ch in sorted(deconvolved_precisions_gauss_cfd.keys(), key=lambda x: x[1]):\n",
    "    val_cfd = deconvolved_precisions_gauss_cfd[p_ch]\n",
    "    val_nn = deconvolved_precisions_gauss_nn[p_ch]\n",
    "    print(\n",
    "        f'{str(p_ch):>7} CFD: {val_cfd:>5.1f} ps, NN: {val_nn:>5.1f} ps, improvement: {(1 - val_nn / val_cfd) * 100:0.2f} %')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Difference histograms: CFD and NN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_global_t = copy.deepcopy(test_dataset.t0)\n",
    "for key in test_dataset.t_pred.keys():\n",
    "    mask = test_dataset.notnan_mask[key]\n",
    "    dataset_global_t[key][mask] += test_dataset.t_pred[key][mask]\n",
    "\n",
    "plt.figure(figsize=(13, 5))\n",
    "plt.rc('font', size=12)\n",
    "i_plot = 1\n",
    "for p_ch1, p_ch2 in combinations(dataset_global_t.keys(), 2):\n",
    "    if p_ch1[1] == p_ch2[1]:  # Only for corresponding channels\n",
    "        plt.subplot(2, 4, i_plot)\n",
    "        i_plot += 1\n",
    "        ch1_timestamps, ch2_timestamps = dataset_global_t[p_ch1], dataset_global_t[p_ch2]\n",
    "        differences = [ch2_t - ch1_t for ch1_t, ch2_t in zip(ch1_timestamps, ch2_timestamps) if\n",
    "                       not np.isnan(ch1_t) and not np.isnan(ch2_t)]\n",
    "\n",
    "        std_stat = np.std(differences)\n",
    "        _, std_gauss, _, _ = plot_gauss_hist(np.array(differences), show=False, xlabel='time difference [ns]')\n",
    "        plt.title(f\"(ch {p_ch1[1]}; p {p_ch1[0]} vs p {p_ch2[0]}) std: {std_gauss * 1000:0.0f} ps\")\n",
    "        plt.yticks([0, 50, 100, 150, 200])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.grid()\n",
    "save_plt(ARTIFACT_DIR / 'cfd_pairwise.pdf')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_global_t = copy.deepcopy(test_dataset_updated.t0)\n",
    "for key in test_dataset.t_pred.keys():\n",
    "    mask = test_dataset_updated.notnan_mask[key]\n",
    "    dataset_global_t[key][mask] += test_dataset_updated.t_pred[key][mask]\n",
    "\n",
    "plt.figure(figsize=(13, 5))\n",
    "plt.rc('font', size=12)\n",
    "i_plot = 1\n",
    "for p_ch1, p_ch2 in combinations(dataset_global_t.keys(), 2):\n",
    "    if p_ch1[1] == p_ch2[1]:  # Only for corresponding channels\n",
    "        plt.subplot(2, 4, i_plot)\n",
    "        i_plot += 1\n",
    "        ch1_timestamps, ch2_timestamps = dataset_global_t[p_ch1], dataset_global_t[p_ch2]\n",
    "        differences = [ch2_t - ch1_t for ch1_t, ch2_t in zip(ch1_timestamps, ch2_timestamps) if\n",
    "                       not np.isnan(ch1_t) and not np.isnan(ch2_t)]\n",
    "\n",
    "        std_stat = np.std(differences)\n",
    "        _, std_gauss, _, _ = plot_gauss_hist(np.array(differences), show=False, xlabel='time difference [ns]')\n",
    "        plt.title(f\"(ch {p_ch1[1]}; p {p_ch1[0]} vs p {p_ch2[0]}) std: {std_gauss * 1000:0.0f} ps\")\n",
    "        plt.yticks([0, 50, 100, 150, 200])\n",
    "        plt.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "save_plt(ARTIFACT_DIR / 'nn_pairwise.pdf')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# Pairwise diffs of two-channel averages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compute_pairwise_precisions_2ch(dataset: ExpandedDataset, save_name: str | None):\n",
    "    dataset_cfd_2ch = {}\n",
    "    for p_ch1, p_ch2 in combinations(dataset.keys(), 2):\n",
    "        if p_ch1[1] == p_ch2[1]:  # Only for corresponding channels\n",
    "            ch1_timestamps = dataset.t_pred[p_ch1] + dataset.t0[p_ch1]\n",
    "            ch2_timestamps = dataset.t_pred[p_ch2] + dataset.t0[p_ch2]\n",
    "\n",
    "            dataset_cfd_2ch[(p_ch1, p_ch2)] = (ch1_timestamps + ch2_timestamps) / 2.\n",
    "\n",
    "    plt.figure(figsize=(13, 5))\n",
    "    plt.rc('font', size=12)\n",
    "    i_plot = 1\n",
    "\n",
    "    pairwise_precisions = {}\n",
    "    for (pch11, pch12), (pch21, pch22) in combinations(dataset_cfd_2ch.keys(), 2):\n",
    "        if pch11[1] == pch12[1] == pch21[1] == pch22[1]:\n",
    "            plt.subplot(2, 4, i_plot)\n",
    "            i_plot += 1\n",
    "\n",
    "            ch1_timestamps, ch2_timestamps = dataset_cfd_2ch[(pch11, pch12)], dataset_cfd_2ch[(pch21, pch22)]\n",
    "            differences = [ch2_t - ch1_t for ch1_t, ch2_t in zip(ch1_timestamps, ch2_timestamps) if\n",
    "                           not np.isnan(ch1_t) and not np.isnan(ch2_t)]\n",
    "\n",
    "            _, std_gauss, _, _ = plot_gauss_hist(np.array(differences), show=False)\n",
    "            pairwise_precisions[((pch11, pch12), (pch21, pch22))] = std_gauss * 1000\n",
    "\n",
    "            plt.title(\n",
    "                f\"{pch11[1]}; ({pch11[0]}, {pch12[0]}) vs ({pch21[0]}, {pch22[0]}): std: {std_gauss * 1000:0.0f} ps\")\n",
    "            plt.yticks([0, 150, 300, 450, 600])\n",
    "            plt.grid()\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_name is not None:\n",
    "        save_plt(ARTIFACT_DIR / save_name)\n",
    "    plt.show()\n",
    "\n",
    "    return pairwise_precisions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CFD"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "precisions_2ch_cfd = compute_pairwise_precisions_2ch(test_dataset, 'cfd_2ch_pairwise.pdf')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## NN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "precisions_2ch_nn = compute_pairwise_precisions_2ch(test_dataset_updated, 'nn_2ch_pairwise.pdf')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Improvement"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Gauss:')\n",
    "for key in sorted(precisions_2ch_cfd.keys(), key=lambda x: x[1]):\n",
    "    val_cfd = precisions_2ch_cfd[key]\n",
    "    val_nn = precisions_2ch_nn[key]\n",
    "    print(\n",
    "        f'{str(key):>40} CFD: {val_cfd:>5.1f} ps, NN: {val_nn:>5.1f} ps, improvement: {(1 - val_nn / val_cfd) * 100:0.2f} %')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Deconvolution: TODO"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def _sorted_pair(a, b):\n",
    "    return (a, b) if b > a else (b, a)\n",
    "\n",
    "\n",
    "def deconvolve_precision_2ch(p1: int, p2: int, prec_dict: dict) -> float:\n",
    "    \"\"\"\n",
    "    sigma(1, 2)^2 = sigma(1, 2, 1, 3)^2 + sigma(1, 2, 2, 3)^2 - sigma(1, 3, 2, 3)^2\n",
    "    \"\"\"\n",
    "    pair0 = _sorted_pair(p1, p2)\n",
    "    p3 = list({1, 2, 3} - {p1, p2})[0]\n",
    "    pair1 = _sorted_pair(p1, p3)\n",
    "    pair2 = _sorted_pair(p2, p3)\n",
    "\n",
    "    pos_pair_1 = prec_dict[_sorted_pair(pair0, pair1)]\n",
    "    pos_pair_2 = prec_dict[_sorted_pair(pair0, pair2)]\n",
    "    neg_pair = prec_dict[_sorted_pair(pair1, pair2)]\n",
    "\n",
    "    return math.sqrt((pos_pair_1 ** 2 + pos_pair_2 ** 2 - neg_pair ** 2) / 2)\n",
    "\n",
    "\n",
    "def deconvolve_2ch_all(prec_dict: dict):\n",
    "    channel_mutual_precisions: dict = defaultdict(dict)\n",
    "    for ((ch11, ch12), (ch21, ch22)), precision in prec_dict.items():\n",
    "        assert ch11[1] == ch12[1] == ch21[1] == ch22[1]\n",
    "        channel_mutual_precisions[ch11[1]][((ch11[0], ch12[0]), (ch21[0], ch22[0]))] = precision\n",
    "\n",
    "    deconvolved_precisions = {}\n",
    "    for ch, prec_dict in channel_mutual_precisions.items():\n",
    "        for p1, p2 in combinations(PLANES, 2):\n",
    "            deconvolved_precisions[((p1, ch), (p2, ch))] = deconvolve_precision_2ch(p1, p2, prec_dict)\n",
    "\n",
    "    return deconvolved_precisions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "deconvolved_pairs_2ch_cfd = deconvolve_2ch_all(precisions_2ch_cfd)\n",
    "deconvolved_pairs_2ch_nn = deconvolve_2ch_all(precisions_2ch_nn)\n",
    "\n",
    "print('CFD')\n",
    "pprint(deconvolved_pairs_2ch_cfd)\n",
    "print('NN')\n",
    "pprint(deconvolved_pairs_2ch_nn)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from src.dataset import PlaneChannel\n",
    "\n",
    "\n",
    "def deconvolve_precision(p: int, prec_dict: dict[PlaneChannel, float]) -> float:\n",
    "    \"\"\"\n",
    "    sigma(1)^2 = sigma(1, 2)^2 + sigma(1, 3)^2 - sigma(2, 3)^2\n",
    "    \"\"\"\n",
    "    p1 = (p - PLANE_0 + 1) % N_PLANES + PLANE_0\n",
    "    p2 = (p - PLANE_0 + 2) % N_PLANES + PLANE_0\n",
    "\n",
    "    pos_pair_1 = prec_dict[_sorted_pair(p, p1)]\n",
    "    pos_pair_2 = prec_dict[_sorted_pair(p, p2)]\n",
    "    neg_pair = prec_dict[_sorted_pair(p1, p2)]\n",
    "\n",
    "    print(pos_pair_1, pos_pair_2, neg_pair)\n",
    "    print((pos_pair_1 ** 2 + pos_pair_2 ** 2 - neg_pair ** 2) / 2)\n",
    "    print(math.sqrt((pos_pair_1 ** 2 + pos_pair_2 ** 2 - neg_pair ** 2) / 2))\n",
    "    return math.sqrt((pos_pair_1 ** 2 + pos_pair_2 ** 2 - neg_pair ** 2) / 2)\n",
    "\n",
    "\n",
    "def deconvolve_precisions(prec_dict: dict[tuple[PlaneChannel, PlaneChannel], float]) -> dict[PlaneChannel, float]:\n",
    "    channel_mutual_precisions: dict[int, dict[tuple[int, int], float]] = defaultdict(dict)\n",
    "    for ((x_p, x_ch), (y_p, y_ch)), precision in prec_dict.items():\n",
    "        assert x_ch == y_ch\n",
    "        channel_mutual_precisions[x_ch][(x_p, y_p)] = precision\n",
    "\n",
    "    deconvolved_precisions = {}\n",
    "    for ch, prec_dict in channel_mutual_precisions.items():\n",
    "        for p in PLANES:\n",
    "            deconvolved_precisions[(p, ch)] = deconvolve_precision(p, prec_dict)\n",
    "\n",
    "    return deconvolved_precisions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "deconvolved_2ch_cfd = deconvolve_precisions(deconvolved_pairs_2ch_cfd)\n",
    "deconvolved_2ch_nn = deconvolve_precisions(deconvolved_pairs_2ch_nn)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Gauss:')\n",
    "for p_ch in sorted(deconvolved_precisions_gauss_cfd.keys(), key=lambda x: x[1]):\n",
    "    val_cfd = deconvolved_2ch_cfd[p_ch]\n",
    "    val_nn = deconvolved_2ch_nn[p_ch]\n",
    "    print(\n",
    "        f'{str(p_ch):>7} CFD: {val_cfd:>5.1f} ps, NN: {val_nn:>5.1f} ps, improvement: {(1 - val_nn / val_cfd) * 100:0.2f} %')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
