{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "PWD = '../../..'\n",
    "sys.path.append(PWD)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import callbacks\n",
    "import keras_tuner as kt\n",
    "\n",
    "from src.network_utils import count_params\n",
    "from src.cross_validator import KerasTunerCrossValidator\n",
    "from src.dataset import load_dataset_train_test, load_dataset_train_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "DATASET_PATH = PWD + '/data/dataset/dataset.pkl'\n",
    "TRIALS_DIR = PWD + '/data/tuner'\n",
    "CROSSVAL_DIR = PWD + '/data/cross_val'\n",
    "\n",
    "PLANE = 2\n",
    "CHANNEL = 11\n",
    "\n",
    "PROJECT_NAME = f'mlp_{PLANE}_{CHANNEL}'\n",
    "\n",
    "LR = 0.01\n",
    "\n",
    "N_EPOCHS = 3000\n",
    "BATCH_SIZE = 2048\n",
    "MAX_TRIALS = 40\n",
    "EXECUTIONS_PER_TRIAL = 2\n",
    "\n",
    "TOP_N = 5\n",
    "CROSSVAL_N_CV = 5\n",
    "CROSSVAL_N_EXEC = 2\n",
    "LOSS_WEIGHT = 1000"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "((22412, 24), (17929, 24), (4483, 24))"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_base_train, _, y_base_train, _ = load_dataset_train_test(PWD, PLANE, CHANNEL)\n",
    "X_train, X_val, y_train, y_val = load_dataset_train_val(PWD, PLANE, CHANNEL)\n",
    "\n",
    "X_base_train.shape, X_train.shape, X_val.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def model_builder(hp: kt.HyperParameters) -> keras.Model:\n",
    "    hp_n_hidden_layers = hp.Int(\"n_hidden_layers\", min_value=1, max_value=6, step=1, default=2)\n",
    "    hp_units_mult = hp.Choice(\"units_mult\", values=[1, 2, 4, 8, 16, 32], default=4)\n",
    "    hp_batch_normalization = hp.Boolean(\"batch_normalization\", default=False)\n",
    "    hp_input_batch_normalization = hp.Boolean(\"input_batch_normalization\", default=False)\n",
    "    hp_dropout = hp.Choice(\"dropout\", values=[0.0, 0.1, 0.2])\n",
    "\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Input(24))\n",
    "    if hp_input_batch_normalization:\n",
    "        model.add(layers.BatchNormalization())\n",
    "\n",
    "    n_units = 3 * (2 ** (hp_n_hidden_layers - 1)) * hp_units_mult\n",
    "    for _ in range(hp_n_hidden_layers):\n",
    "        model.add(layers.Dense(n_units, activation='relu'))\n",
    "        n_units //= 2\n",
    "        if hp_batch_normalization:\n",
    "            model.add(layers.BatchNormalization())\n",
    "        if hp_dropout > 0:\n",
    "            model.add(layers.Dropout(hp_dropout))\n",
    "\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    model.compile(loss='mse', optimizer=optimizers.Adam(LR), loss_weights=LOSS_WEIGHT)\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 24)                600       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 12)                300       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 913\n",
      "Trainable params: 913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_builder(kt.HyperParameters()).summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "model_callbacks = [\n",
    "    callbacks.EarlyStopping(patience=50),\n",
    "    callbacks.ReduceLROnPlateau(monitor='loss', factor=0.9, patience=10),\n",
    "    callbacks.TensorBoard(\"/tmp/tb_logs/bayesian/\" + PROJECT_NAME)\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Bayesian tuner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 40 Complete [00h 00m 31s]\n",
      "val_loss: 8.98246145248413\n",
      "\n",
      "Best val_loss So Far: 8.571378707885742\n",
      "Total elapsed time: 00h 21m 12s\n"
     ]
    }
   ],
   "source": [
    "bayesian_tuner = kt.BayesianOptimization(model_builder, objective='val_loss', executions_per_trial=EXECUTIONS_PER_TRIAL,\n",
    "                                         max_trials=MAX_TRIALS, directory=TRIALS_DIR + \"/bayesian\",\n",
    "                                         project_name=PROJECT_NAME, overwrite=False)\n",
    "\n",
    "bayesian_tuner.search(X_base_train, y_base_train, validation_split=0.2, epochs=N_EPOCHS, callbacks=model_callbacks,\n",
    "                      batch_size=BATCH_SIZE, verbose=3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in ../../../data/tuner/bayesian\\mlp_2_11\n",
      "Showing 1 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x0000027143A49CF0>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_hidden_layers: 4\n",
      "units_mult: 8\n",
      "batch_normalization: True\n",
      "input_batch_normalization: True\n",
      "dropout: 0.2\n",
      "Score: 8.571378707885742\n"
     ]
    }
   ],
   "source": [
    "bayesian_tuner.results_summary(1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization (BatchN  (None, 24)               96        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 192)               4800      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 192)              768       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 192)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 96)                18528     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 96)               384       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 96)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 48)                4656      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 48)               192       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 48)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 24)                1176      \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 24)               96        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 24)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 25        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,721\n",
      "Trainable params: 29,953\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model = bayesian_tuner.get_best_models(num_models=1)[0]\n",
    "best_model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Model 0 ==========\n",
      "{'n_hidden_layers': 4, 'units_mult': 8, 'batch_normalization': True, 'input_batch_normalization': True, 'dropout': 0.2}\n",
      "Number of parameters: 29953\n",
      "========== Model 1 ==========\n",
      "{'n_hidden_layers': 3, 'units_mult': 4, 'batch_normalization': False, 'input_batch_normalization': True, 'dropout': 0.0}\n",
      "Number of parameters: 2737\n",
      "========== Model 2 ==========\n",
      "{'n_hidden_layers': 1, 'units_mult': 32, 'batch_normalization': False, 'input_batch_normalization': True, 'dropout': 0.2}\n",
      "Number of parameters: 2545\n",
      "========== Model 3 ==========\n",
      "{'n_hidden_layers': 1, 'units_mult': 32, 'batch_normalization': True, 'input_batch_normalization': True, 'dropout': 0.2}\n",
      "Number of parameters: 2737\n",
      "========== Model 4 ==========\n",
      "{'n_hidden_layers': 5, 'units_mult': 16, 'batch_normalization': False, 'input_batch_normalization': True, 'dropout': 0.0}\n",
      "Number of parameters: 411697\n"
     ]
    }
   ],
   "source": [
    "for i, hyperparameters in enumerate(bayesian_tuner.get_best_hyperparameters(TOP_N)):\n",
    "    print(f'========== Model {i} ==========')\n",
    "    print(hyperparameters.get_config()['values'])\n",
    "    model_tmp = model_builder(hyperparameters)\n",
    "    print('Number of parameters:', count_params(model_tmp))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in ../../../data/tuner/bayesian\\mlp_2_11\n",
      "Showing 5 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x0000027143A49CF0>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_hidden_layers: 4\n",
      "units_mult: 8\n",
      "batch_normalization: True\n",
      "input_batch_normalization: True\n",
      "dropout: 0.2\n",
      "Score: 8.571378707885742\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_hidden_layers: 3\n",
      "units_mult: 4\n",
      "batch_normalization: False\n",
      "input_batch_normalization: True\n",
      "dropout: 0.0\n",
      "Score: 8.589727401733398\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_hidden_layers: 1\n",
      "units_mult: 32\n",
      "batch_normalization: False\n",
      "input_batch_normalization: True\n",
      "dropout: 0.2\n",
      "Score: 8.590714931488037\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_hidden_layers: 1\n",
      "units_mult: 32\n",
      "batch_normalization: True\n",
      "input_batch_normalization: True\n",
      "dropout: 0.2\n",
      "Score: 8.593961715698242\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_hidden_layers: 5\n",
      "units_mult: 16\n",
      "batch_normalization: False\n",
      "input_batch_normalization: True\n",
      "dropout: 0.0\n",
      "Score: 8.60997486114502\n"
     ]
    }
   ],
   "source": [
    "bayesian_tuner.results_summary(TOP_N)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cross-validation for top 5 models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Model 0</h3>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_hidden_layers': 4, 'units_mult': 8, 'batch_normalization': True, 'input_batch_normalization': True, 'dropout': 0.2}\n",
      "Number of parameters: 29953\n",
      "Got score: 8.6960 (8.6609, 8.7311)\n",
      "Got score: 8.3512 (8.3741, 8.3284)\n",
      "Got score: 8.1229 (8.1064, 8.1393)\n",
      "Got score: 8.4067 (8.3944, 8.4191)\n",
      "Got score: 8.7155 (8.6960, 8.7351)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Model 1</h3>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_hidden_layers': 3, 'units_mult': 4, 'batch_normalization': False, 'input_batch_normalization': True, 'dropout': 0.0}\n",
      "Number of parameters: 2737\n",
      "Got score: 8.8446 (8.8814, 8.8078)\n",
      "Got score: 8.6175 (8.5951, 8.6399)\n",
      "Got score: 8.2877 (8.3585, 8.2168)\n",
      "Got score: 8.5512 (8.6143, 8.4881)\n",
      "Got score: 8.8314 (8.8635, 8.7993)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Model 2</h3>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_hidden_layers': 1, 'units_mult': 32, 'batch_normalization': False, 'input_batch_normalization': True, 'dropout': 0.2}\n",
      "Number of parameters: 2545\n",
      "Got score: 8.8180 (8.6709, 8.9651)\n",
      "Got score: 8.3381 (8.3566, 8.3197)\n",
      "Got score: 8.1193 (8.1428, 8.0958)\n",
      "Got score: 8.4218 (8.4380, 8.4055)\n",
      "Got score: 8.7505 (8.7030, 8.7980)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Model 3</h3>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_hidden_layers': 1, 'units_mult': 32, 'batch_normalization': True, 'input_batch_normalization': True, 'dropout': 0.2}\n",
      "Number of parameters: 2737\n",
      "Got score: 8.7369 (8.6635, 8.8102)\n",
      "Got score: 8.5558 (8.6334, 8.4782)\n",
      "Got score: 8.3401 (8.4918, 8.1884)\n",
      "Got score: 8.5635 (8.5709, 8.5561)\n",
      "Got score: 8.8504 (8.8071, 8.8936)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Model 4</h3>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_hidden_layers': 5, 'units_mult': 16, 'batch_normalization': False, 'input_batch_normalization': True, 'dropout': 0.0}\n",
      "Number of parameters: 411697\n",
      "Got score: 8.7897 (8.8513, 8.7281)\n",
      "Got score: 8.3864 (8.3457, 8.4270)\n",
      "Got score: 8.3028 (8.3325, 8.2731)\n",
      "Got score: 8.5401 (8.6465, 8.4337)\n",
      "Got score: 8.9012 (8.9223, 8.8801)\n"
     ]
    }
   ],
   "source": [
    "cross_validator = KerasTunerCrossValidator(bayesian_tuner, X_base_train, y_base_train, model_builder,\n",
    "                                           directory=CROSSVAL_DIR, project_name=PROJECT_NAME,\n",
    "                                           n_epochs=N_EPOCHS, batch_size=BATCH_SIZE, n_top=TOP_N,\n",
    "                                           n_cv=CROSSVAL_N_CV, n_executions=CROSSVAL_N_EXEC, overwrite=False)\n",
    "model_scores = cross_validator()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "       mean   std  n_params\nModel                      \n0      8.46  0.22     29953\n1      8.63  0.20      2737\n2      8.49  0.26      2545\n3      8.61  0.17      2737\n4      8.58  0.23    411697",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean</th>\n      <th>std</th>\n      <th>n_params</th>\n    </tr>\n    <tr>\n      <th>Model</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8.46</td>\n      <td>0.22</td>\n      <td>29953</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8.63</td>\n      <td>0.20</td>\n      <td>2737</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8.49</td>\n      <td>0.26</td>\n      <td>2545</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8.61</td>\n      <td>0.17</td>\n      <td>2737</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8.58</td>\n      <td>0.23</td>\n      <td>411697</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_scores = [f\"{np.mean(scores):0.2f}\" for scores in model_scores.values()]\n",
    "std_scores = [f\"{np.std(scores):0.2f}\" for scores in model_scores.values()]\n",
    "n_params = [count_params(model_builder(hyperparameters)) for hyperparameters in\n",
    "            bayesian_tuner.get_best_hyperparameters(TOP_N)]\n",
    "\n",
    "df = pd.DataFrame({'mean': mean_scores, 'std': std_scores, 'n_params': n_params}, index=model_scores.keys())\n",
    "df.index.name = 'Model'\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
